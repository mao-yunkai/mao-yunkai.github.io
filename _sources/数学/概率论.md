# 概率论
统计学是对真实世界的采样，统计学得到的只是频率，通过大数定律，将统计数据转为概率，进而利用概率密度函数，引入分析学进行分析，从而找出统计数据中的性质。
## 速查表

| 概念        | 公式                                                                                                     | 说明                                                                                                                         |
| --------- | ------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------- |
| 随机变量      | $X$                                                                                                    | 样本空间随机采样得到的变量                                                                                                              |
| 分布律       | $P(X=x)$                                                                                               | 离散型随机变量使用分布律描述变量取值概率的规律                                                                                                    |
| 分布函数      | $F(X)=P(X\leq x)$                                                                                      | 连续随机变量使用分布函数描述随机变量的统计规律性                                                                                                   |
| 概率密度函数    | $f(x)=F'(x)$<br>$f(x)=\lim_{\Delta x\to0^{+}}\frac{P\{x<X\leqslant x+\Delta x\}}{\Delta x}$            | 连续型随机变量的概率密度函数可以理解为离散型随机变量的分布律，表示变量取某值的概率<br>                                                                              |
| 联合分布律     | $P(X=x, Y=y)$                                                                                          | 多维离散随机变量的描述方式                                                                                                              |
| 联合分布函数    | $F(x,y)=P(X\leq x, Y\leq y)$                                                                           | 多维连续随机变量的分布函数                                                                                                              |
| 联合概率密度    | $f(x,y)=\frac{\partial^2F(x,y)}{\partial x\partial y}$                                                 | 多维随机变量的概率密度                                                                                                                |
| 边缘分布函数    | $F_X(x)=F(x, \infty)$<br>$F_Y(y)=F(\infty, y)$                                                         | 多维随机变量子集的概率的计算方式                                                                                                           |
| 边缘分布律     | $P(X=x)=\Sigma_j P(X=x, Y=y_j)$<br>$P(Y=y)=\Sigma _i P(X=x_i, Y=y)$                                    |                                                                                                                            |
| 边缘概率密度    | $f_X(x)=\int_{-\infty}^\infty f(x,y) \mathrm{d}y$<br>$f_Y(y)=\int_{-\infty}^\infty f(x,y) \mathrm{d}x$ |                                                                                                                            |
| 条件分布律     | $P(X\mid Y)=\frac{P(X,Y)}{P(Y)}$                                                                       |                                                                                                                            |
| 条件概率密度    | $f_{X\mid Y}(x\mid y)=\frac{f(x,y)}{f_{Y}(y)}$                                                         |                                                                                                                            |
| 相互独立的随机变量 | $F(x,y)=F_X(x)F_Y(y)$<br>$f(x,y)=f_X(x)f_Y(y)$                                                         | 相互独立的随机变量，联合概率密度的计算公式从$f(x,y)=f_Y(y)f_{X\mid Y}(x\mid y)$变成了$f(x,y)=f_X(x)f_Y(y)$。相当于X不依赖于Y，$f_X(x)=f_{X\mid Y}(x\mid y)$。 |
## 基本概念
在个别试验中其结果呈现出不确定性，在大量重复试验中其结果又具有统计规律性的现象，我们称之为随机现象。概率论和数理统计是研究和揭示随机现象统计规律性的一门数学学科。
### 样本空间
随机试验满足以下三个特点
1. 可以在相同的条件下重复地进行；
2. 每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果；
3. 进行一次试验之前不能确定哪一个结果会出现
随机试验$E$的所有可能结果组成的集合称为$E$的样本空间，记为$S$。样本空间的元素称为样本点。试验$E$的样本空间$S$的子集为$E$的随机事件。在每次试验中，当且仅当这一子集中的一个样本点出现时，称这一事件发生。由一个样本点组成的单点集，称为基本事件。
4. $A\subset B$，则称事件B包含事件A，这指的是事件A发生必导致事件B发生。
5. 若$A\subset B$且$B\subset A$，则称事件A与事件B相等。
6. 事件$A\cup B={x|x\in A或x\in B}$称为事件$A$与事件$B$的和事件。当且仅当$A$和$B$中至少有一个发生时，事件$A\cup B$发生。
### 频率与概率
在相同条件下，进行了$n$次试验，在这$n$次试验中，事件A发生的次数$n_A$称为事件$A$发生的频数。比值$n_A/n$称为事件$A$发生的频率，并记成$f_n(A)$。
设$E$是随机试验，$S$是它的样本空间。对于$E$ 的每一事件$A$赋予一个实数，记为$P(A)$，称为事件$A$的概率，如果集合函数$P(\cdot)$满足下列条件：  
1. 非负性：对于每一个事件 $A$，有$P(A)\geqslant0;$
2. 规范性：对于必然事件 $S$，有 $P(S) = 1$ ;
3. 可列可加性：设 $A_1,A_2,\cdotp\cdotp\cdotp$是两两互不相容的事件，即对于 $A_iA_j=\varnothing$,
$i\neq j,i,j=1,2,\cdots$,有
$$P(A_{1}\cup A_{2}\cup\cdots)=P(A_{1})+P(A_{2})+\cdots.$$
古典概型有两个特点：
4. 试验的样本空间只包含有限个元素；
5. 试验中每个基本事件发生的可能性相同。
### 条件概率
设试验的基本事件总数为$n$，$A$所包含的基本事件数为$m(m>0)$，$AB$所包含的基本事件数为$k$，即有
$$ P(B|A) = \frac{k}{m} = \frac{k/n}{m/n} =\frac{P(AB)}{P(A)} $$
### 乘法公式
设$P(A)>0$，则有
$$ P(AB) = P(B|A)P(A) $$
### 全概率公式
设试验$E$的样本空间为$S$，$A$为$E$的事件，$B_1,B_2, \cdots, B_n$为S的一个划分，且$P(B_i)>0(i=1,2,\cdots,n)$，则全概率公式为
$$ P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \cdots + P(A|B_n)P(B_n) $$
### 贝叶斯公式
设试验$E$的样本空间为$S$。$A$为$E$的事件，$B_1,B_2,\cdots,B_n$为$S$的一
个划分，且 $P(A)>0,P(B_{i})>0(i=1,2,\cdots,n)$，则贝叶斯公式为
$$P(B_{i}\mid A)=\frac{P(A\mid B_{i})P(B_{i})}{\sum_{i=1}^{n}P(A\mid B_{j})P(B_{j})},\quad i=1,2,\cdots,n.$$
特别地，若将$n=2$，并将$B_1$记为$B$，$B_2$记为$\bar B$，那么，全概率公式和贝叶斯公式分别为
$$ P(A) = P(A\mid B)P(B) + P(A\mid\bar B)P(\bar B) $$
$$ P(B\mid A)=\frac{P(A\mid B)P(B)}{P(A)}=\frac{P(A\mid B)P(B)}{P(A\mid B)P(B)+P(A\mid\bar B)P(\bar B)} $$
### 独立性
设$A,B$是两事件，如果满足等式
$$ P(AB)=P(A)P(B) $$
则称事件$A,B$相互独立，简称$A,B$独立
## 随机变量
设随机试验的[[#样本空间]]为$S={e}$。$X=X(e)$是定义在样本空间$S$上的实值单值函数。称$X=X(e)$为随机变量。
### 离散型随机变量
离散型随机变量的全部可能取到的值是有限个或可列无限多个。
设离散型随机变量$X$所有可能取的值为$x_k(k=1,2,\cdotp\cdotp\cdotp)$，$X$取各个可能值的概率，即事件$\{X=x_k\}$的概率，为
$$P\{X=x_{k}\}=p_{k},\:k=1,2,\cdots.$$
- $p_k\ge0$
- $\sum_{k=1}^{n}p_{k}=1$
- $0-1$分布  
    随机变量$X$只可能取0与1两个值，其分布律为
    $$P\{ X = k \} = p^{k} ( 1 - p )^{1 - k} ,k = 0 ,1\quad( 0 < p < 1 )$$
- 二项分布 / 伯努利分布  
    $P(A)=p, P(\bar A)=1-p$， 将试验$E$独立重复$n$次，称这一串重复的独立试验为$n$重伯努利试验。以$X$表示$n$重伯努利试验中事件$A$发生的次数，随机变量$X$的分布律为
    $$P\{ X = k \} = \sum_{k=0}^n p^{k} \binom{n}{k} ( 1 - p )^{n - k} ,k = 0 ,1,\cdots,n$$
    称随机变量$X$服从参数为$n,p$的二项分布，并记为$X\sim b(n,p)$
- 泊松分布  
    设随机变量 $X$ 所有可能取的值为 $0,1,2,\cdotp\cdotp\cdotp$,而取各个值的概率为
    $$P\{X=k\}=\frac{\lambda^{k}\mathrm{e}^{-\lambda}}{k!},\:k=0,1,2,\cdots,$$
    其中 $\lambda>0$ 是常数.则称 X 服从参数为$\lambda$ 的泊松分布，记为$X\sim\pi(\lambda).$
  - 以$n,p$为参数的二项分布的概率值可以由参数为$\lambda=np$的泊松分布的概率值近似。
### 连续型随机变量
设$X$是一个随机变量$,x$是任意实数，函数
$$F(x)=P\{X{\leqslant}x\}\:,\:-\infty<x<\infty $$
称为 $X$ 的分布函数。
如果对于随机变量$X$的分布函数$F(x)$，存在非负函数 $f(x)$，使对于任意实数 $x$ 有
$$F(x)=\int_{-\infty}^xf(t)\:\mathrm{d}t\:,$$
则称$X$为连续型随机变量，其中函数 $f(x)$称为$X$ 的概率密度函数，简称概率密度。

- 均匀分布  
    若连续型随机变量$X$具有概率密度
    $$f(x)=\begin{cases}\dfrac{1}{b-a},&a<x<b,\\[2ex]0\:,&\text{其他,}\end{cases}$$
    则称$X$在区间($a,b$)上服从均匀分布.记为$X\sim U(a,b)$
- 指数分布  
    若连续型随机变量 X 的概率密度为
    $$f(x)=\begin{cases}\dfrac{1}{\theta}\mathrm{e}^{-x/\theta},x>0,\\[2ex]0,\quad\text{其他,}\end{cases}$$
    其中$\theta>0$为常数，则称 X 服从参数为$\theta$的指数分布.
- 正态分布  
    若连续型随机变量 X 的概率密度为
    $$f(x)=\frac{1}{\sqrt{2\pi}\:\sigma}\mathrm{e}^{-\frac{(x-\mu)^{2}}{2}}\:,-\infty<x<\infty\:$$
    其中$\mu,\sigma(\sigma>0)$为常数，则称 $X$ 服从参数为 $\mu , \sigma$ 的 正 态分布或高斯(Gauss)分布，记为$X\sim N(\mu,\sigma^{2}).$
- 随机变量的函数的分布  
    设随机变量$X$具有概率密度$f_x(x),-\infty< x < \infty $,又设函数$g(x)$ 处处可导且恒有 $g^\prime(x)>0$ (或恒有 $g^\prime(x)<0$),则 $Y=g(X)$是连续型随机变量， 其概率密度为
    $$f_Y(y)=\begin{cases}f_X\bigl[h(y)\bigr]\bigl[h^{'}(y)\bigr],&\alpha<y<\beta,\\0,&\text{其他,}\end{cases}$$
    其中$\alpha=\min\{g(-\infty),g(\infty)\},\beta=\max\{g(-\infty),g(\infty)\},h(y)$是$g(x)$的反函数。

## 多维随机变量及其分布
设$(X,Y)$是二维随机变量，对于任意实数 $x,y$二元函数：
$$F(x,y)=P\{(X\leqslant x)\cap(Y\leqslant y)\}\xLeftrightarrow{\text{记成}}P\{X\leqslant x,Y\leqslant y\}$$
称为二维随机变量$(X,Y)$的分布函数，或称为随机变量$X$和$Y$的联合分布函数。

我们称 $P\{X=x_i,Y=y_j\}=p_{ij},i,j=1,2,\cdotp\cdotp\cdotp$为二维离散型随机变量$(X,Y)$的分布律，或随机变量$X$和$Y$的联合分布律。可以用表格表示为

| Y\X | 1    | 2    | 3    | 4    |
| --- | ---- | ---- | ---- | ---- |
| 0   | 1/10 | 0    | 0    | 0    |
| 1   | 0    | 4/10 | 2/10 | 1/10 |
| 2   | 0    | 0    | 0    | 2/10 |
二维随机变量$(X,Y)$的分布函数 $F(x,y)=\int_{-\infty}^y\int_{-\infty}^xf(u,v) \mathrm{d}u\mathrm{d}v$ 称为随机变量$X$和$Y$的联合概率密度。
以上关于二维随机变量的讨论可以扩展到$n$维随机变量的情况。
### 边缘分布
二维随机变量$(X,Y)$具有分布函数$F(X,Y)$，随机变量$X$，$Y$分别有分布函数$F_x(X)$，$F_y(Y)$，依次称为二维随机变量$(X,Y)$关于$X$和$Y$的边缘分布函数。
$$ F_{X}(x)=P\{X\leqslant x\}=P\{X\leqslant x,Y<\infty\}=F(x,\infty) $$
- 离散型随机变量

$$ F_{X}(x)=F(x,\infty)=\sum_{x_{i}\leqslant x}\sum_{j=1}^{\infty}p_{ij}. $$
我们常常将边缘分布律写在联合分布律表格地边缘上，这就是“边缘分布律”这个名词的来源。

| Y\X        | 1    | 2    | 3    | 4    | $P\{Y=y\}$ |
| ---------- | ---- | ---- | ---- | ---- | ---------- |
| 0          | 1/10 | 0    | 0    | 0    | 1/10       |
| 1          | 0    | 4/10 | 2/10 | 1/10 | 7/10       |
| 2          | 0    | 0    | 0    | 2/10 | 2/10       |
| $P\{X=x\}$ | 1/10 | 4/10 | 2/10 | 3/10 | 1          |

- 连续型随机变量
$$ F_X(x)=F(x,\infty)=\int_{-\infty}^{x}\biggl[\int_{-\infty}^{\infty}f(x,y) \mathrm{d}y\biggr] \mathrm{d}x $$
随机变量$(X,Y)$关于$X$的边缘概率密度为
$$ f_X(x)=\int_{-\infty}^{\infty}f(x,y) \mathrm{d}y $$
### 条件分布
- 离散型随机变量  
定义 设($X,Y$)是二维离散型随机变量，对于固定的$j$,若$P\{Y=y_j\}>0$,
则称
$$P\langle\:X=x_i\:|\:Y=y_j\:\rangle=\frac{P\langle\:X=x_i\:,Y=y_j\:\rangle}{P\langle\:Y=y_j\:\rangle}=\frac{p_{ij}}{p\:._j}\:,i=1\:,2\:,\cdots$$
为在$Y=y_{j}$条件下随机变量$X$的条件分布律.

- 连续型随机变量  
定义 设二维随机变量($X,Y$)的概率密度为 $f(x,y),(X,Y)$关于$Y$ 的边缘概率密度为 $f_Y(y).$ 若对于固定的 $y,f_Y(y)>0$,则称$\frac {f(x,y)}{f_Y(y)}$为在 $Y= y$ 的条件下 $X$ 的条件概率密度，记为

$$f_{X|Y}(x\mid y)=\frac{f(x,y)}{f_{Y}(y)}.$$
### 相互独立的随机变量
设$F(x,y)$及$F_X(x),F_Y(y)$分别是二维随机变量$(X,Y)$的分布函数及边缘分布函数.若对于所有$x,y$有
$$P\{X\leqslant x,Y\leqslant y\}=P\{X\leqslant x\}P\{Y\leqslant y\}$$
即
$$F(x,y)=F_{X}(x)F_{Y}(y)\:,$$
则称随机变量 X 和 Y 是相互独立的  
对于连续型随机变量
$$f(x,y)=f_X(x)f_Y(y)$$
## 随机变量分布的数字特征
### 期望
设离散型随机变量$X$的分布律为$P\{X=x_k\}=p_k,k=1,2,\cdots$，若级数$\sum_{k=1}^{\infty}x_kp_k$绝对收敛，则称级数的和为随机变量$X$的数学期望，记为$E(X)$。
$$ E(X)=\sum_{k=1}^{\infty}x_kp_k$$
设连续型随机变量X的概率密度为$f(x)$，若积分$\int_{-\infty}^{\infty}xf(x)\mathrm{d}x$绝对收敛，则称积分的值为随机变量$X$的数学期望，记为$E(X)$。
$$ E(X)=\int_{-\infty}^{\infty}xf(x)\mathrm{d}x $$
- 设$C$是常数，则有$E(C)=C$
- 设$X$是一个随机变量，$C$是常数，则有$E(CX)=CE(X)$
- 设$X$和$Y$是两个随机变量，则有$E(X+Y)=E(X)+E(Y)$
- 设$X$和$Y$是相互独立的随机变量，则有$E(XY)=E(X)E(Y)$
### 方差
设$X$是一个随机变量，若$E\{[X-E(X)]^2\}$存在，则称为$X$的方差，记为$D(X)$或$Var(X)$。
$$ D(X)=Var(x)=E\{[X-E(X)]^2\}=E(X^2)-[E(X)]^2 $$
- 设$C$是常数，则$D(C)=0$
- 设$X$是随机变量，$C$是常数，则有
$$ D(CX)=C^2D(X) $$
$$ D(X+C)=D(X) $$
- 设$X$和$Y$是两个随机变量，则有
$$ D(X+Y)=D(X)+D(Y)+2E\{(X-E(X))(Y-E(Y))\} $$
特别，若$X$，$Y$相互独立，则有
$$ D(X+Y)=D(X)+D(Y) $$
- $D(X)=0$的充要条件是$X$以概率 1 取常数$E(X)$,即
$$P\{X{=}E(X)\}{=}1$$
- 切比雪夫不等式给出了在随机变量$X$的分布未知，只知道$E(X)$和$D(X)$的情况下，对事件$\{X-E(X)\}\leqslant\varepsilon$概率的下限的估计
$$ P\{|X-\mu|\geqslant\varepsilon\}\leqslant\frac{\sigma^2}{\varepsilon^2} $$

二维随机变量(X,Y)具有分布函数F(x,y)，X、Y各自的分布函数$F_x(X)$，$F_y(Y)$称为边缘分布函数。
$$F_x(x)=P\{X\leq x, Y<\infty\}=F(x,\infty)$$
$$F_y(y)=P\{Y\leq y, X<\infty\}=F(\infty,y)$$
### 协方差
量$E\{[X-E(X)][Y-E(Y)]\}$称为随机变量$X$和$Y$的协方差，记为$Cov(X,Y)$。
$$ \mathrm{Cov}(X,Y)=E\{\begin{bmatrix}X-E(X)\end{bmatrix}\begin{bmatrix}Y-E(Y)\end{bmatrix}\} $$
随机变量$X$和$Y$的相关系数为
$$ \rho_{XY}=\frac{\mathrm{Cov}(X,Y)}{\sqrt{D(X)} \sqrt{D(Y)}} $$

- $D(X+Y)=D(X)+D(Y)+2\mathrm{Cov}(X,Y).$
- $\mathrm{Cov}(aX,bY)=ab\mathrm{Cov}(X,Y),a,b$是常数
- $\mid\rho_{XY}\mid\leqslant1$
- $|\rho_{XY}|=1$ 的充要条件是，存在常数 $a,b$ 使
    $$P\{Y=a+bX\}=1$$
- $\rho_{XY}$是一个可以用来表征$X$，$Y$之间线性关系紧密程度的量，值越大相关程度越高。$\rho_{XY}=0$时，$X$，$Y$不相关。
### 矩
设$X$和$Y$是随机变量，若 $E( X^{k}),k= 1, 2, \cdotp \cdotp \cdotp$ 存在，称它为$X$的$k$阶原点矩，简称$k$阶矩。  
若 $E\{\begin{bmatrix}X-E(X)\end{bmatrix}^{k}\},k=2,3,\cdots$ 存在，称它为 $X$ 的$k$ 阶中心矩。  
若 $E(X^kY^l)\:, k,l=1,2,\cdots$ 存在，称它为 $X$ 和$Y$的$k+l$阶混合矩。  
若 $E\{ [ X- E( X) ] ^{k}[ Y- E( Y) ] ^l\} , k, l= 1, 2, \cdots$ 存在，称它为$X$和$Y$的$k+l$阶混合中心矩。  

设$n$维随机变量( $X_1,X_2,\cdotp\cdotp\cdotp,X_n$)的二阶混合中心矩
$c_{ij}=Cov(X_i,X_j)=E\{[X_i-E(X_i)][X_j-E(X_j)]\},i,j=1,2,\cdots,n$
都存在，则称矩阵
$$\mathbf{C}=\begin{bmatrix}c_{11}&c_{12}&\cdots&c_{1n}\\c_{21}&c_{22}&\cdots&c_{2n}\\\vdots&\vdots&&\vdots\\c_{n1}&c_{n2}&\cdots&c_{nn}\end{bmatrix}$$
为$n$维随机变量$(X_1,X_2,\cdotp\cdotp\cdotp,X_n$)的协方差矩阵.由于$c_ij=c_{ji}(i\neq j;i,j=1,2,\cdotp\cdotp\cdotp,n$),因而上述矩阵是一个对称矩阵。
## 大数定律及中心极限定理
大数定理是叙述随机变量序列的前一些项的算术平均值在某种条件下收敛到这些项的均值的算术平均值。  
中心极限定理是确定在什么条件下，大量随机变量之和的分布逼近于正态分布。
### 大数定律
频率的稳定性是概率定义的客观基础，本节目的是对频率的稳定性作出理论的说明。
#### 依概率收敛
设$Y_1,Y_2,\cdots,Y_n,\cdots$是一个随机变量序列$,a$ 是一个常数.若对于任意正数
$\varepsilon$,有
$$\lim_{n\to\infty}P\{\mid Y_n-a\mid<\varepsilon\}\:=\:1$$
则称序列$Y_1,Y_2,\cdots,Y_n,\cdots$依概率收敛于$a$,记为
$$Y_{n}\xrightarrow{P}a$$

- 设 $X_n\xrightarrow{P}a,Y_n\xrightarrow{P}b$，又设函数 $g(x,y)$在点$(a,b)$连续，则$g(X_{n},Y_{n})\xrightarrow{P}g(a,b)$。
#### 辛钦大数定理
设随机变量 $X_1,X_2,\cdotp\cdotp\cdotp,X_n,\cdotp\cdotp\cdotp$相互独立，服从同一分布且具有数学期望$E(X_k)=\mu(k=1,2,\cdots)$,则序列$\overline{X}=\frac1n\sum_{k=1}^nX_k$依概率收敛于 $\mu$,即 $\overline{X}\xrightarrow P\mu$。

$$ \lim_{n\to\infty}P\left\{\left|\frac{1}{n}\sum_{k=1}^{n}X_{k}-\mu\right|<\varepsilon\right\}=1 $$
对于独立同分布且具有均值$\mu$的随机变量$X_1,X_2,\cdots$，当$n$很大时它们的算术平均$\frac{1}{n}\sum_{k=1}{n}X_k$ 很可能接近于$\mu$。
#### 伯努利大数定理
$$ \lim_{n\to\infty}P\left\{\left|\frac{f_{A}}{n}-p\right|<\varepsilon\right\}=1 $$
对于给定的任意小的正数$\varepsilon$，事件“频率$\frac{f_A}{n}$与概率$p$的偏差小于$\varepsilon$”实际上几乎是必定要发生的。这就是频率稳定性的真正含义。在实际应用中，当试验次数很大时，便可以用事件的频率来代替事件的概率。
### 中心极限定理
#### 独立同分布的中心极限定理
均值为$\mu$，方差为$\sigma^2>0$的独立同分布的随机变量$X_1, X_2, \cdots, X_n$之和$\bar X =\sum_{k=1}{n}X_k$的标准化变量，当$n$充分大时，有
$$ \bar X \sim N(\mu, \sigma^2/n) $$
近似地服从均值为$\mu$，方差为$\sigma^2/n$的正态分布。
#### 李雅普诺夫定理
无论各个随机变量$X_k$服从什么分布，只要满足定理的条件，那么它们的和$\sum_{k=1}^nX_k$当$n$足够大时，就近似的服从正态分布。在很多问题中，所考虑的随机变量可以表示称很多个独立的随机变量之和，它们往往近似地服从正态分布。
#### 拉普拉斯定理

$$ \lim_{n\to\infty}P\left\{\frac{\eta_{n}-np}{\sqrt{np\left(1-p\right)}}\leqslant x\right\}=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^{2}/2}\mathrm{d}t=\Phi(x) $$

定理表明，正态分布是二项分布的极限分布。
## 排列与组合
### 排列数
$$ A_n^m=n(n-1)\ldots(n-m+1)=\frac{n!}{(n-m)!} $$
### 组合数
每一个组合在$m$个位置上都能有$m!$个排列，因此要除以$m!$去掉重复的情况。

$$ C_n^m=\frac{n(n-1)\ldots(n-m+1)}{m!}=\frac{n!}{m!(n-m)!} $$

