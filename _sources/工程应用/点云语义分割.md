# 点云语义分割
## 问题定义
给定数据集包含$N$张点云帧$\{(P_i,L_i)|i = 1,\ldots,N\}$，其中$P_i\in\mathbb{R}^{n_i\times4}$是第$i$张点云帧，包含$n_i$个点，每个点定义为$(x,y,z,reflection)$， $(x,y,z)$表示点的笛卡尔坐标值，reflection表示反射强度。$L_i \in \mathbb{Z}^{n_i}$包含每个点的语义标签值。
我们的目标是学习一个函数$f(\cdot;\theta)$，$f(P_i)$输出与$L_i$之间的误差达到最小。
## 数据集


| 数据集           | 链接                                                                                                                         |
| ------------- | -------------------------------------------------------------------------------------------------------------------------- |
| SemanticKITTI | [SemanticKITTI - A Dataset for LiDAR-based Semantic Scene Understanding](https://semantic-kitti.org/dataset.html#download) |
| Waymo         | [3D Semantic Segmentation – 2024 – Waymo Open Dataset](https://waymo.com/open/challenges/2024/3d-semantic-segmentation/)   |
| nuScenes      | [nuScenes](https://www.nuscenes.org/nuscenes#overview)                                                                     |
| S3DIS         | [http://buildingparser.stanford.edu/dataset.html](http://buildingparser.stanford.edu/dataset.html)                         |

## 数据结构
### Octree
[Octree - Open3D 0.19.0 documentation](https://www.open3d.org/docs/release/tutorial/geometry/octree.html)
八叉树是将三维数据进行划分存储的一种方式。将一个体素格进行分割，能够分成八个子格子，因此八叉树的八个子节点即父节点分成的子格子。若格子内无点，则不需要继续分割，否则可以继续分割，直到每个叶子节点都只有一个点。
### KDTree
[KDTree - Open3D 0.19.0 documentation](https://www.open3d.org/docs/release/tutorial/geometry/kdtree.html)
KD树可以用于最近邻搜索。输入K维数据，按不同维度依方差顺序找均值划分二叉树，即KD树。最近邻搜索时，依坐标值找到叶子节点，若距离小于均值，则叶子节点是最近邻，否则再查找下一分支。

## 数据处理
### Farthest Point Sampling
最远点采样是一种采样方法，目的是使采样尽可能的离散均匀。算法流程是：
1. 随机选取一个点加入采样集合
2. 寻找剩余点中与采样集合的距离最远的点，加入采样集合
3. 计算点与采样集合中所有点的的距离，最短距离即点与采样集合的距离
4. 重复以上步骤直到采样到足够点
最远点采样需要三重for循环（采样点、剩余点、点与已采样点距离），因此计算量大，速度慢，优点是采样均匀，能够保持三维形状特征。
## 算法模型
### Point Transformer
Point Transformer使用Transformer架构进行点云语义分割，提出了向量注意力的概念。缩放点积注意力使用点积计算查询和键之间的关系，而向量注意力用减法衡量二者之间的关系。

$$\begin{align}
softmax(\mathrm{MLP}(Q-K)+\delta)(V+\delta)\\
\delta = \mathrm{MLP}(p_i-p_j)
\end{align}$$
这样做的好处是与价值向量相乘的不再是一个点积标量而是一个向量，表达能力更强。
### Point Transformer V2
PTv1的缺点是，随着数据规模的上升，参数规模也会变得非常大。因此PTv2提出了一个折中的办法，就是用分组的向量注意力机制，将一个向量分成几块，每块共享一个参数。
另一个改进点是，PTv1的时候，用的是kNN查询近邻向量作为一个子集进行注意力训练，大量的时间花在了kNN查询中。因此，PTv2划分了网格，直接将网格内的点作为一个子集训练注意力。
### Point Transformer V3
[GitHub - Pointcept/Pointcept: Pointcept: a codebase for point cloud perception research. Latest works: Sonata (CVPR'25 Highlight), PTv3 (CVPR'24 Oral), PPT (CVPR'24), MSC (CVPR'23)](https://github.com/Pointcept/Pointcept)
使用点云序列化的方式加速了模型的推理过程，利用固定的模式将三维点云映射到一维，每个点云都有一个下标，且相邻下标的点在几何上距离相近，这样就省去了在三维空间查找的时间。
## 加速优化
### Flash Attention
[Dao-AILab/flash-attention: Fast and memory-efficient exact attention](https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file)
利用GPU的SRAM、HBM和CPUDRAM的处理带宽和容量的差异，将QKV向量分块后使用SRAM计算sm(QK)V的值。关键是使用safe softmax进行分块后的注意力值计算公式。
[torch.nn.functional.scaled_dot_product_attention — PyTorch 2.2 documentation](https://docs.pytorch.org/docs/2.2/generated/torch.nn.functional.scaled_dot_product_attention.html)
Flash Attention目前已经集成到pytorch中。
## 评价指标
Intersection over Union (IoU) 是指对于某个类别，其预测结果与真实标签之间重叠部分的面积与两者总面积的比例。
$$ IoU = \frac{Area\ of\ Overlap}{Area\ of\ Union}=\frac{TP}{TP+FP+FN}$$
整体精度$mIoU$是所有类别$IoU$的均值。
快速计算$mIoU$的方法：
```Python
def fast_hist(pred, label, n):
    mask = (label >= 0) & (label < n)
    bin_count=np.bincount(
        n * label[mask].astype(int) + pred[mask], minlength=n ** 2)
    return bin_count[:n ** 2].reshape(n, n)
    
def per_class_iu(hist):
    return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
```
- fast_hist用来快速构建混淆矩阵。
- mask是一个布尔数组，用来筛选label中在0到n之间的元素。
- `n*label+pred`是一个值，取值范围在$n**2$之间，可以唯一映射到一个`(n,n)`的二维数组， `n*label`表示label值对应的行，加上pred值表示pred值对应的列。
- bincount统计值出现的次数，使用该方法统计所有值出现的频数，将其转换成二维数组，即可得到混淆矩阵。
- per_class_iu用来计算每个类的iou。iou值是对角线值除以行列之和，分母分别累和行列需要减去一个多加的对角线值。
