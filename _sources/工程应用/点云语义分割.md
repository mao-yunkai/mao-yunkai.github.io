# 点云语义分割
## 问题定义
给定数据集包含$N$张点云帧$\{(P_i,L_i)|i = 1,\ldots,N\}$，其中$P_i\in\mathbb{R}^{n_i\times4}$是第$i$张点云帧，包含$n_i$个点，每个点定义为$(x,y,z,reflection)$， $(x,y,z)$表示点的笛卡尔坐标值，reflection表示反射强度。$L_i \in \mathbb{Z}^{n_i}$包含每个点的语义标签值。
我们的目标是学习一个函数$f(\cdot;\theta)$，$f(P_i)$输出与$L_i$之间的误差达到最小。
## 数据集

| 数据集           | 链接                                                                                                                         |
| ------------- | -------------------------------------------------------------------------------------------------------------------------- |
| SemanticKITTI | [SemanticKITTI - A Dataset for LiDAR-based Semantic Scene Understanding](https://semantic-kitti.org/dataset.html#download) |
| Waymo         | [3D Semantic Segmentation – 2024 – Waymo Open Dataset](https://waymo.com/open/challenges/2024/3d-semantic-segmentation/)   |
| nuScenes      | [nuScenes](https://www.nuscenes.org/nuscenes#overview)                                                                     |
| S3DIS         | [http://buildingparser.stanford.edu/dataset.html](http://buildingparser.stanford.edu/dataset.html)                         |
## 数据结构
### Octree
[Octree - Open3D 0.19.0 documentation](https://www.open3d.org/docs/release/tutorial/geometry/octree.html)
八叉树是将三维数据进行划分存储的一种方式。将一个体素格进行分割，能够分成八个子格子，因此八叉树的八个子节点即父节点分成的子格子。若格子内无点，则不需要继续分割，否则可以继续分割，直到每个叶子节点都只有一个点。
### KDTree
[KDTree - Open3D 0.19.0 documentation](https://www.open3d.org/docs/release/tutorial/geometry/kdtree.html)
KD树可以用于最近邻搜索。输入K维数据，按不同维度依方差顺序找均值划分二叉树，即KD树。最近邻搜索时，依坐标值找到叶子节点，若距离小于均值，则叶子节点是最近邻，否则再查找下一分支。

## 数据处理
### Farthest Point Sampling
最远点采样是一种采样方法，目的是使采样尽可能的离散均匀。算法流程是：
1. 随机选取一个点加入采样集合
2. 寻找剩余点中与采样集合的距离最远的点，加入采样集合
3. 计算点与采样集合中所有点的的距离，最短距离即点与采样集合的距离
4. 重复以上步骤直到采样到足够点
最远点采样需要三重for循环（采样点、剩余点、点与已采样点距离），因此计算量大，速度慢，优点是采样均匀，能够保持三维形状特征。
## 算法模型
### PointNet
项目地址：[charlesq34/pointnet: PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://github.com/charlesq34/pointnet)
Pytorch复现代码地址：<https://github.com/yanx27/Pointnet_Pointnet2_pytorch>
贡献：
1. 首先用神经网络处理三维数据的模型。
2. 使用最大池化层提取特征，解决了数据无序性问题。
3. 成为了后续3D点云特征提取的基础模型。
Pointnet的做法是随机选择点云中一个点作为中心点，然后生成一个框，用np.where选择框内的点作为数据块，将局部相对位置（原点在中心点）与全局绝对位置（原点在点云帧原点）联合，然后用conv1d进行学习。
### PointNet++
项目地址：[charlesq34/pointnet2: PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://github.com/charlesq34/pointnet2)
Pytorch复现代码地址：<https://github.com/yanx27/Pointnet_Pointnet2_pytorch>
贡献：
1. 使用了Unet结构，提高了预测精度。
方法：
2. 划分网格，用网格图作为最小训练单位。
3. 每个网格固定采样点数，点数不够重采样，点数太多降采样。
4. 最后形成固定大小的数据帧，输入到模型中，输入是N个点，每个具有d维坐标与C维特征。
5. Set Abstraction 操作是指从N个点中选择N1个中心点（sampling）构建具有重叠区域的邻域（grouping），每个邻域中具有K个点（不固定，用Pointnet转成固定长度特征向量），然后提取出C1个特征值，数据从(N, d+C)变成(N1, K, d+C1)。模型使用了类似Unet的结构，逐层向下卷积再反卷积。
6. FeaturePropagation层首先计算两层输入点坐标之间的距离，然后用第四层的三个最近邻点加权来表示第三层的点，这样就得到了与第三层个数相同的新点。
7. 新点得到的512个特征与第三层点的512个特征合并，得到768个特征。将特征输入到模型中，得到输出结果。
### PolarNet
项目地址：[edwardzhou130/PolarSeg: Implementation for PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation (CVPR 2020)](https://github.com/edwardzhou130/PolarSeg)
贡献：
1. 首先使用极坐标表示法表示点云数据，然后根据极坐标分割体素，优势是与雷达的近密远疏的特征适配，解决了稀疏体素块过多导致效率低下的问题。
2. 使用Random Sample替换了Farthest Point Sample。
3. 简单，快速，高效
方法：
4. 将数据变换成极坐标表示方式，使用极坐标划分体素。
5. 在极坐标体素上进行卷积。
6. 其他与基于体素的UNet结构方法类似。
### Point Transformer
Point Transformer使用Transformer架构进行点云语义分割，提出了向量注意力的概念。缩放点积注意力使用点积计算查询和键之间的关系，而向量注意力用减法衡量二者之间的关系。

$$\begin{align}
softmax(\mathrm{MLP}(Q-K)+\delta)(V+\delta)\\
\delta = \mathrm{MLP}(p_i-p_j)
\end{align}$$
这样做的好处是与价值向量相乘的不再是一个点积标量而是一个向量，表达能力更强。
### Point Transformer V2
PTv1的缺点是，随着数据规模的上升，参数规模也会变得非常大。因此PTv2提出了一个折中的办法，就是用分组的向量注意力机制，将一个向量分成几块，每块共享一个参数。
另一个改进点是，PTv1的时候，用的是kNN查询近邻向量作为一个子集进行注意力训练，大量的时间花在了kNN查询中。因此，PTv2划分了网格，直接将网格内的点作为一个子集训练注意力。
### Point Transformer V3
[GitHub - Pointcept/Pointcept: Pointcept: a codebase for point cloud perception research. Latest works: Sonata (CVPR'25 Highlight), PTv3 (CVPR'24 Oral), PPT (CVPR'24), MSC (CVPR'23)](https://github.com/Pointcept/Pointcept)
使用点云序列化的方式加速了模型的推理过程，利用固定的模式将三维点云映射到一维，每个点云都有一个下标，且相邻下标的点在几何上距离相近，这样就省去了在三维空间查找的时间。
## 加速优化
### Flash Attention
[Dao-AILab/flash-attention: Fast and memory-efficient exact attention](https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file)
利用GPU的SRAM、HBM和CPUDRAM的处理带宽和容量的差异，将QKV向量分块后使用SRAM计算sm(QK)V的值。关键是使用safe softmax进行分块后的注意力值计算公式。
[torch.nn.functional.scaled_dot_product_attention — PyTorch 2.2 documentation](https://docs.pytorch.org/docs/2.2/generated/torch.nn.functional.scaled_dot_product_attention.html)
Flash Attention目前已经集成到pytorch中。
## 评价指标
Intersection over Union (IoU) 是指对于某个类别，其预测结果与真实标签之间重叠部分的面积与两者总面积的比例。
$$ IoU = \frac{Area\ of\ Overlap}{Area\ of\ Union}=\frac{TP}{TP+FP+FN}$$
整体精度$mIoU$是所有类别$IoU$的均值。
快速计算$mIoU$的方法：
```Python
def fast_hist(pred, label, n):
    mask = (label >= 0) & (label < n)
    bin_count=np.bincount(
        n * label[mask].astype(int) + pred[mask], minlength=n ** 2)
    return bin_count[:n ** 2].reshape(n, n)
    
def per_class_iu(hist):
    return np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))
```
- fast_hist用来快速构建混淆矩阵。
- mask是一个布尔数组，用来筛选label中在0到n之间的元素。
- `n*label+pred`是一个值，取值范围在$n**2$之间，可以唯一映射到一个`(n,n)`的二维数组， `n*label`表示label值对应的行，加上pred值表示pred值对应的列。
- bincount统计值出现的次数，使用该方法统计所有值出现的频数，将其转换成二维数组，即可得到混淆矩阵。
- per_class_iu用来计算每个类的iou。iou值是对角线值除以行列之和，分母分别累和行列需要减去一个多加的对角线值。
